# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zGgCKjwfawmKsU_DH1OTqd0T20uFEgxG
"""

!pip install streamlit

import pandas as pd
from datetime import datetime, timedelta
import random

# Generate 20 rows of dummy data
data = {
    'id': [f"1kn{''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=4))}" for _ in range(20)],
    'Topic': [
        "US reportedly plans to slash bank rules", "More than 1,000 Starbucks baristas go on strike",
        "Harvardâ€™s copy of Magna Carta is accessible", "Mother allegedly buys ammunition, tactical gear",
        "UnitedHealth under criminal probe", "State leaders prepare for post Roe v. Wade",
        "Walmart warns of higher prices", "Girl escapes captivity from New Jersey",
        "US transportation secretary changed wifeâ€™s file", "Mayor proposes anti-theft policy",
        "Viral TikTok shows looting in broad daylight", "Online trolls target transgender student",
        "High school student assaulted", "Online bullying spikes after school closure",
        "Reddit user shares suicide story", "News outlet covers school shooting aftermath",
        "Teen victim speaks out about bullying", "Local protest against online abuse",
        "AI-generated fake news spreads hate", "Platform rolls out new safety feature"
    ],
    'text': [None]*20,
    'url': [f"https://newswebsite.com/article/{i}" for i in range(20)],
    'Score': [random.randint(100, 50000) for _ in range(20)],
    'Comments': [random.randint(5, 2000) for _ in range(20)],
    'Subreddit': random.choices(['news', 'politics', 'technology', 'education', 'socialmedia'], k=20),
    'timestamp_utc': [(datetime.now() - timedelta(days=random.randint(0, 3), hours=random.randint(0, 23))).strftime('%Y-%m-%d %H:%M:%S') for _ in range(20)],
    'Platform': ['Reddit'] * 20,
    'Bullying': random.choices([0, 1], weights=[0.7, 0.3], k=20),
    'Date': [(datetime.now() - timedelta(days=random.randint(0, 3))).strftime('%Y-%m-%d') for _ in range(20)],
    'Hour': [random.randint(0, 23) for _ in range(20)],
}

df = pd.DataFrame(data)

# Show the DataFrame
df.head(20)

import streamlit as st
import pandas as pd
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from transformers import RobertaTokenizer, RobertaForSequenceClassification
import torch
import sqlite3


import pandas as pd
from datetime import datetime, timedelta
import random

# Generate 20 rows of dummy data
data = {
    'id': [f"1kn{''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=4))}" for _ in range(20)],
    'Topic': [
        "US reportedly plans to slash bank rules", "More than 1,000 Starbucks baristas go on strike",
        "Harvardâ€™s copy of Magna Carta is accessible", "Mother allegedly buys ammunition, tactical gear",
        "UnitedHealth under criminal probe", "State leaders prepare for post Roe v. Wade",
        "Walmart warns of higher prices", "Girl escapes captivity from New Jersey",
        "US transportation secretary changed wifeâ€™s file", "Mayor proposes anti-theft policy",
        "Viral TikTok shows looting in broad daylight", "Online trolls target transgender student",
        "High school student assaulted", "Online bullying spikes after school closure",
        "Reddit user shares suicide story", "News outlet covers school shooting aftermath",
        "Teen victim speaks out about bullying", "Local protest against online abuse",
        "AI-generated fake news spreads hate", "Platform rolls out new safety feature"
    ],
    'text': [None]*20,
    'url': [f"https://newswebsite.com/article/{i}" for i in range(20)],
    'Score': [random.randint(100, 50000) for _ in range(20)],
    'Comments': [random.randint(5, 2000) for _ in range(20)],
    'Subreddit': random.choices(['news', 'politics', 'technology', 'education', 'socialmedia'], k=20),
    'timestamp_utc': [(datetime.now() - timedelta(days=random.randint(0, 3), hours=random.randint(0, 23))).strftime('%Y-%m-%d %H:%M:%S') for _ in range(20)],
    'Platform': ['Reddit'] * 20,
    'Bullying': random.choices([0, 1], weights=[0.7, 0.3], k=20),
    'Date': [(datetime.now() - timedelta(days=random.randint(0, 3))).strftime('%Y-%m-%d') for _ in range(20)],
    'Hour': [random.randint(0, 23) for _ in range(20)],
}

df = pd.DataFrame(data)


# Add dummy label if not present (in case no labelling yet)
if 'label' in df.columns:
    df.rename(columns={'label': 'Bullying'}, inplace=True)
else:
    df['Bullying'] = 0

df['Bullying'] = pd.to_numeric(df['Bullying'], errors='coerce').fillna(0).astype(int)
df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'], errors='coerce')
df['Date'] = df['timestamp_utc']
df['Hour'] = df['timestamp_utc'].dt.hour

st.title("ğŸ“Š Social Media Bullying Trends Dashboard")

# === Sidebar Filters ===
st.sidebar.header("ğŸ” Filter Data")
date_range = st.sidebar.date_input(
    "Select Date Range",
    [df['Date'].min(), df['Date'].max()]
)

platforms = st.sidebar.multiselect("Platforms", df['Platform'].unique(), default=df['Platform'].unique())
subreddits = st.sidebar.multiselect("Subreddits", df['Subreddit'].unique(), default=df['Subreddit'].unique())
bullying_only = st.sidebar.checkbox("Show only bullying posts")

# === Apply Filters ===
start_date, end_date = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
mask = (
    (df['timestamp_utc'] >= start_date) &
    (df['timestamp_utc'] <= end_date) &
    (df['Platform'].isin(platforms)) &
    (df['Subreddit'].isin(subreddits))
)
if bullying_only:
    mask &= df['Bullying'] == 1

filtered_df = df[mask]

# === User Input for Classification ===
st.markdown("### ğŸ“ Enter a Post Title or Comment to Check for Bullying")
user_input = st.text_area("Enter text here:")

#if user_input:
#    prediction, confidence = is_bullying_model(user_input)
#    if prediction == 1:
#        st.success(f"âœ… This is likely **cyberbullying** (Confidence: {confidence:.2%})")
#    else:
#        st.info(f"ğŸ” This doesn't appear to be bullying (Confidence: {confidence:.2%})")

# === KPIs ===
st.markdown("### ğŸ“Œ Key Metrics")
col1, col2, col3, col4 = st.columns(4)
col1.metric("Total Posts", len(filtered_df))
col2.metric("% Bullying Posts", f"{(filtered_df['Bullying'].mean()) * 100:.1f}%")
col3.metric("Most Active Subreddit", filtered_df['Subreddit'].mode().values[0] if not filtered_df.empty else "N/A")
col4.metric("Top Platform", filtered_df['Platform'].mode().values[0] if not filtered_df.empty else "N/A")

# === Trend Chart ===
st.markdown("### ğŸ“ˆ Bullying Trend by Month and Year")
filtered_df.loc[:, 'Year-Month'] = filtered_df['timestamp_utc'].dt.to_period('M').astype(str)
trend_monthly = filtered_df[filtered_df['Bullying'] == 1].groupby('Year-Month').size().reset_index(name='Bullying Posts')
fig_trend_monthly = px.line(trend_monthly, x='Year-Month', y='Bullying Posts',
                            title="Bullying Posts per Month and Year",
                            labels={'Year-Month': 'Month and Year', 'Bullying Posts': 'Number of Bullying Posts'})
fig_trend_monthly.update_layout(xaxis_title="Month and Year", yaxis_title="Bullying Posts")
st.plotly_chart(fig_trend_monthly, use_container_width=True)

# === Top Subreddits Bar Chart ===
st.markdown("### ğŸ“Š Top Subreddits by Bullying Posts")
subreddit_stats = filtered_df[filtered_df['Bullying'] == 1]['Subreddit'].value_counts().reset_index()
subreddit_stats.columns = ['Subreddit', 'Bullying Posts']
fig_subreddit = px.bar(subreddit_stats, x='Subreddit', y='Bullying Posts', title="Top Subreddits with Bullying Posts")
st.plotly_chart(fig_subreddit, use_container_width=True)

# === Engagement: Score vs Comments ===
st.markdown("### ğŸ”¥ Engagement by Score vs Comments")
fig_engagement_bar = px.bar(
    filtered_df,
    x='Score',
    y='Comments',
    color=filtered_df['Bullying'].map({1: 'Bullying', 0: 'Non-Bullying'}),
    hover_data=['Topic', 'Subreddit', 'url'],
    title="Score vs Comments Engagement (Bar Chart)"
)
st.plotly_chart(fig_engagement_bar, use_container_width=True)

# === Word Cloud ===
st.markdown("### ğŸ§  Word Cloud of Topics")
if not filtered_df.empty and filtered_df['Topic'].notna().any():
    wordcloud_data = ' '.join(filtered_df['Topic'].dropna().astype(str))
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(wordcloud_data)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    st.pyplot(plt)
else:
    st.warning("No text data available for the word cloud with the current filters.")


# 1. Number of Bullying Posts by Date
st.subheader("1. Number of Bullying Posts by Date")
bully_by_date = df[df['Bullying'] == 1].groupby('Date').size().reset_index(name='Bullying Posts')
fig1 = px.bar(bully_by_date, x='Date', y='Bullying Posts', title='Bullying Posts Over Time')
st.plotly_chart(fig1, use_container_width=True)

# 2. Bullying vs Non-Bullying by Subreddit
st.subheader("2. Bullying vs Non-Bullying by Subreddit")
bully_by_subreddit = df.groupby(['Subreddit', 'Bullying']).size().reset_index(name='Count')
fig2 = px.bar(bully_by_subreddit, x='Subreddit', y='Count', color='Bullying',
              barmode='group', title='Bullying vs Non-Bullying Posts by Subreddit')
st.plotly_chart(fig2, use_container_width=True)

# 3. Avg Comments & Posts by Bullying Label
st.subheader("3. Average Comments & Posts (Bullying vs Non-Bullying)")
agg_df = df.groupby('Bullying').agg({
    'Comments': 'mean',
    'id': 'count'
}).rename(columns={'id': 'Total Posts'}).reset_index()
agg_df['Bullying'] = agg_df['Bullying'].map({0: 'Non-Bullying', 1: 'Bullying'})
fig3 = px.bar(agg_df.melt(id_vars='Bullying', var_name='Metric', value_name='Average'),
              x='Bullying', y='Average', color='Metric', barmode='group',
              title='Avg. Comments & Total Posts by Bullying Label')
st.plotly_chart(fig3, use_container_width=True)

# 4. Top 5 Subreddits of the Month
st.subheader("4. Top 5 Subreddits of the Month")
month = st.selectbox("Select Month", sorted(df['Date'].dt.strftime("%Y-%m").unique(), reverse=True))
top_subs = df[df['Date'].dt.strftime("%Y-%m") == month].groupby('Subreddit').size().nlargest(5).reset_index(name='Post Count')
fig4 = px.bar(top_subs, x='Subreddit', y='Post Count', title=f'Top 5 Subreddits in {month}')
st.plotly_chart(fig4, use_container_width=True)

# Optional: Show raw data
if st.checkbox("Show raw data"):
    st.write(df.head(20))
